{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remote test on Sagemaker SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's locally but aws SDK needs a default profile setup \n",
    "# If you already have this, you can safelly ignore this step\n",
    "%env AWS_DEFAULT_REGION=<your region>\n",
    "%env AWS_DEFAULT_PROFILE=<your profile>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = boto3.Session()\n",
    "sm = sess.client('sagemaker')\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with Model on S3\n",
    "model_dir = 's3://<your-bucket>/<prefix>/model.tar.gz'\n",
    "image = '<your image hosted on ECR repository>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wrapper(endpoint, session):\n",
    "    return Predictor(endpoint, session)\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image,\n",
    "    role=role,\n",
    "    model_data=model_dir,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    predictor_cls=predict_wrapper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_serializer\n",
    "\n",
    "print('Deploying endpoint')\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    serializer=json_serializer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import cv2\n",
    "#import requests\n",
    "\n",
    "from PIL import Image\n",
    "import json\n",
    "import base64\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(\"./desk.jpg\")\n",
    "plt.figure(figsize = (60,20))\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Image to send\n",
    "img = Image.open(\"desk.jpg\")\n",
    "\n",
    "#Convert Pillow Image to bytes and then to base64\n",
    "buffered = BytesIO()\n",
    "img.save(buffered, format=\"JPEG\")\n",
    "img_byte = buffered.getvalue() # bytes\n",
    "img_base64 = base64.b64encode(img_byte) #Base64-encoded bytes * not str\n",
    "\n",
    "#It's still bytes so json.Convert to str to dumps(Because the json element does not support bytes type)\n",
    "img_str = img_base64.decode('utf-8') # str\n",
    "\n",
    "files = json.dumps({\n",
    "    \"labels\":\"cup,mouse\", #change to labels that will be detected\n",
    "    \"img\":img_str\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detectron2 to load response\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "import jsonpickle\n",
    "\n",
    "metadata = MetadataCatalog.get(\"__unused\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = jsonpickle.decode(result)\n",
    "\n",
    "v = Visualizer(im[:, :, ::-1], metadata)\n",
    "out = v.draw_instance_predictions(frame[\"instances\"].to(\"cpu\"))\n",
    "plt.figure(figsize = (60,20))\n",
    "plt.imshow(out.get_image())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save Prediction Image\n",
    "im = Image.fromarray(out.get_image())\n",
    "im.save(\"desk_prediction.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting \n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "a667341281b95407f21c4aae9c1d488b3fa194f0587f67c2c36dbfac3e08dffe"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
